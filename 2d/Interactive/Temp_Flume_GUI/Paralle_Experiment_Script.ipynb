{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DirectView [0, 1, 2, 3,...]>\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import ipyparallel\n",
    "import os\n",
    "rc = ipyparallel.Client(profile=\"mpi\")\n",
    "view = rc[:]\n",
    "view.apply(os.chdir, os.getcwd())\n",
    "view['stop'] = True\n",
    "print view\n",
    "\n",
    "view.block=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] MPI rank: 13/20\n",
      "[stdout:1] MPI rank: 2/20\n",
      "[stdout:2] MPI rank: 7/20\n",
      "[stdout:3] MPI rank: 17/20\n",
      "[stdout:4] MPI rank: 5/20\n",
      "[stdout:5] MPI rank: 8/20\n",
      "[stdout:6] MPI rank: 10/20\n",
      "[stdout:7] MPI rank: 18/20\n",
      "[stdout:8] MPI rank: 14/20\n",
      "[stdout:9] MPI rank: 1/20\n",
      "[stdout:10] MPI rank: 0/20\n",
      "[stdout:11] MPI rank: 4/20\n",
      "[stdout:12] MPI rank: 3/20\n",
      "[stdout:13] MPI rank: 16/20\n",
      "[stdout:14] MPI rank: 12/20\n",
      "[stdout:15] MPI rank: 15/20\n",
      "[stdout:16] MPI rank: 6/20\n",
      "[stdout:17] MPI rank: 11/20\n",
      "[stdout:18] MPI rank: 19/20\n",
      "[stdout:19] MPI rank: 9/20\n"
     ]
    }
   ],
   "source": [
    "%%px --block\n",
    "from mpi4py import MPI\n",
    "mpi = MPI.COMM_WORLD\n",
    "bcast = mpi.bcast\n",
    "barrier = mpi.barrier\n",
    "rank = mpi.rank\n",
    "\n",
    "\n",
    "# Engines Imports\n",
    "import sys\n",
    "#!pwd   # Replace sys.path.append with this path\n",
    "sys.path.append('/home/user/JorgeMijares/air-water-vv/2d/Interactive/Temp_Flume_GUI')\n",
    "\n",
    "import proteus\n",
    "## Required imports\n",
    "from proteus.iproteus import * \n",
    "from proteus.mprans import SpatialTools as st\n",
    "from petsc4py import PETSc\n",
    "from threading import Thread\n",
    "import tempFlume as plant\n",
    "import tempFlume_so as plant_so\n",
    "from proteus import default_n, default_s, default_so, Comm, Context\n",
    "print \"MPI rank: %i/%i\" % (mpi.rank,mpi.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Kernel Imports\n",
    "import parUtilities\n",
    "reload(parUtilities)\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Kernel and Engines imports\n",
    "#with view.sync_imports():  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Parameters\n",
    "dt=0.1            # Not sure if disabled, more testing needed, assign same value as dtOut too\n",
    "cfl=0.75          # Not working yet, modify too in tempflume.py\n",
    "dtOut=0.1          # Modify nDTout\n",
    "T=0.2             # Total Simulation Time\n",
    "Tank_he=0.03        # Domain he\n",
    "Caisson_he=0.03     # Interpolation distance of caisson perimeter\n",
    "enSphere=False        # Replace Caisson with sphere for testing of parameters\n",
    "radius=0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Update Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed=1.19723063299, Depth=0.0725714285714, Offset=0.0164112, Scale=21\n",
      "Simulation Started\n"
     ]
    },
    {
     "ename": "CompositeError",
     "evalue": "one or more exceptions from call to method: _pull\n[0:apply]: PicklingError: Can't pickle <type 'module'>: attribute lookup __builtin__.module failed\n[1:apply]: PicklingError: Can't pickle <type 'module'>: attribute lookup __builtin__.module failed\n[2:apply]: PicklingError: Can't pickle <type 'module'>: attribute lookup __builtin__.module failed\n[3:apply]: PicklingError: Can't pickle <type 'module'>: attribute lookup __builtin__.module failed\n.... 16 more exceptions ...",
     "output_type": "error",
     "traceback": [
      "[0:apply]: ",
      "\u001b[0;31m\u001b[0m\u001b[0;31mPicklingError\u001b[0mTraceback (most recent call last)\u001b[0;32m/home/user/JorgeMijares/proteus/linux2/lib/python2.7/site-packages/ipyparallel/serialize/serialize.pyc\u001b[0m in \u001b[0;36mserialize_object\u001b[0;34m(obj, buffer_threshold, item_threshold)\u001b[0m",
      "\u001b[1;32m    110\u001b[0m         \u001b[0mbuffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mbuffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPICKLE_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <type 'module'>: attribute lookup __builtin__.module failed",
      "",
      "[1:apply]: ",
      "\u001b[0;31m\u001b[0m\u001b[0;31mPicklingError\u001b[0mTraceback (most recent call last)\u001b[0;32m/home/user/JorgeMijares/proteus/linux2/lib/python2.7/site-packages/ipyparallel/serialize/serialize.pyc\u001b[0m in \u001b[0;36mserialize_object\u001b[0;34m(obj, buffer_threshold, item_threshold)\u001b[0m",
      "\u001b[1;32m    110\u001b[0m         \u001b[0mbuffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mbuffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPICKLE_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <type 'module'>: attribute lookup __builtin__.module failed",
      "",
      "[2:apply]: ",
      "\u001b[0;31m\u001b[0m\u001b[0;31mPicklingError\u001b[0mTraceback (most recent call last)\u001b[0;32m/home/user/JorgeMijares/proteus/linux2/lib/python2.7/site-packages/ipyparallel/serialize/serialize.pyc\u001b[0m in \u001b[0;36mserialize_object\u001b[0;34m(obj, buffer_threshold, item_threshold)\u001b[0m",
      "\u001b[1;32m    110\u001b[0m         \u001b[0mbuffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mbuffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPICKLE_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <type 'module'>: attribute lookup __builtin__.module failed",
      "",
      "[3:apply]: ",
      "\u001b[0;31m\u001b[0m\u001b[0;31mPicklingError\u001b[0mTraceback (most recent call last)\u001b[0;32m/home/user/JorgeMijares/proteus/linux2/lib/python2.7/site-packages/ipyparallel/serialize/serialize.pyc\u001b[0m in \u001b[0;36mserialize_object\u001b[0;34m(obj, buffer_threshold, item_threshold)\u001b[0m",
      "\u001b[1;32m    110\u001b[0m         \u001b[0mbuffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mbuffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPICKLE_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <type 'module'>: attribute lookup __builtin__.module failed",
      "",
      "... 16 more exceptions ..."
     ]
    }
   ],
   "source": [
    "\n",
    "#Experimental Case\n",
    "\n",
    "Scales = [21,25]        # Scale could be 21 or 25\n",
    "index  = 44             #Refer to DoE_TempFlume.xlsx to check case conditions\n",
    "scale  = 21\n",
    "#for s_ind, scale in enumerate(Scales):\n",
    "if True:\n",
    "# Base Model, replace the model with tempFlume_test for testing\n",
    "# tempFlume is the most stable version until now.\n",
    "        xl    = pd.ExcelFile(\"DoE_TempFlume.xlsx\")\n",
    "        df1   = xl.parse(0)\n",
    "        df2   = xl.parse(1)\n",
    "        df3   = xl.parse(2)\n",
    "        df4   = xl.parse(3, header=0, index_col=0)\n",
    "        df5   = xl.parse(4, header=0, index_col=0)\n",
    "        \n",
    "\n",
    "        clear_output()\n",
    "\n",
    "        reload(plant)\n",
    "        reload(plant_so)\n",
    "\n",
    "        if scale == 21:\n",
    "            df_DoE  = df4\n",
    "            df_data = df2\n",
    "\n",
    "        elif scale==25:\n",
    "            df_DoE  = df5\n",
    "            df_data = df3\n",
    "        else:\n",
    "            print 'Wrong Scale'\n",
    "            () + 1\n",
    "        #for index in range(view.pull('df4', targets=0).shape[0]):\n",
    "        if True:\n",
    "            test_name     = 'Results/S{0}T{1}'.format(scale,index)\n",
    "            status        = df_DoE['Finished'].tolist()[index]\n",
    "            #if status == 'Completed':\n",
    "            #    continue\n",
    "            \n",
    "            # Read Index from DoE table\n",
    "            iFlow   = df_DoE['Flow Speed'].tolist()[index]\n",
    "            iDepth  = df_DoE['Depth'].tolist()[index]\n",
    "            iOffset = df_DoE['Offset'].tolist()[index]\n",
    "            \n",
    "            # Read Tag parameters from table\n",
    "            tagFlow   = df_data['Speed Tags'].tolist()[iFlow]\n",
    "            tagDepth  = df_data['Depth Tags'].tolist()[iDepth]\n",
    "            tagOffset = df_data['Offset Tags'].tolist()[iOffset]\n",
    "            \n",
    "            # Read parameters from table\n",
    "            flowSpeed  = df_data['Flow Speed'].tolist()[iFlow]\n",
    "            waterLevel = df_data['Depth'].tolist()[iDepth]\n",
    "            offset     = df_data['Offset'].tolist()[iOffset]\n",
    "            \n",
    "            #Change Context\n",
    "            view['plant.opts.water_level'] = waterLevel\n",
    "            view['plant.opts.tank_dim']    = (3.0,waterLevel+0.5)\n",
    "\n",
    "            # plant.opts.wind_velocity=(flowSpeed,0.)\n",
    "            view['plant.opts.inflow_velocity'] = flowSpeed\n",
    "            # plant.opts.outflow_velocity=flowSpeed\n",
    "            view['plant.opts.caisson_scale']   = float(scale)\n",
    "            view['plant.opts.caisson_Yoffset'] = -offset\n",
    "            \n",
    "            view['plant.opts.dtOut']        = dtOut\n",
    "            view['plant.opts.sphere']       = enSphere\n",
    "            view['plant.opts.sphereRadius'] = radius\n",
    "            view['plant.opts.dt_fixed']     = dt\n",
    "            view['plant.opts.cfl']          = cfl\n",
    "            view['plant.opts.T']            = T\n",
    "            view['plant.opts.he']           = Tank_he\n",
    "            view['plant.opts.he_caisson']   = Caisson_he\n",
    "\n",
    "            print 'Speed={0}, Depth={1}, Offset={2}, Scale={3}'.format(\n",
    "                                                flowSpeed,\n",
    "                                                waterLevel,\n",
    "                                                offset,\n",
    "                                                scale)\n",
    "            def Setup_Simulation():\n",
    "                global ct,ns, simulation_thread\n",
    "                plant.Update_Model()\n",
    "                Context.setFromModule(plant,mutable=True)\n",
    "                ct = Context.get()\n",
    "                plant_so.ct =ct\n",
    "                \n",
    "                so = plant_so\n",
    "                so.tnList = [0.0]+[i*plant.opts.dtOut for i in range(1,plant.nDTout+1)]        \n",
    "                info = open(\"TimeList.txt\",\"w\")\n",
    "                for time in so.tnList:\n",
    "                    info.write(str(time)+\"\\n\")\n",
    "                info.close()\n",
    "                plant_so.tnList=so.tnList\n",
    "                pList=[]\n",
    "                nList=[]\n",
    "                so.sList=[]\n",
    "                OptDB = PETSc.Options()\n",
    "                for (p,n) in so.pnList:\n",
    "                    so.sList.append(default_s)\n",
    "                    pList.append(__import__(p))\n",
    "                    reload(pList[-1])\n",
    "                    nList.append(__import__(n))\n",
    "                    reload(nList[-1])\n",
    "                    pList[-1].name = p\n",
    "                    nList[-1].multilevelLinearSolver = default_n.KSP_petsc4py\n",
    "                    nList[-1].levelLinearSolver = default_n.KSP_petsc4py\n",
    "                    OptDB.setValue(nList[-1].linear_solver_options_prefix+\"ksp_type\", \"preonly\")\n",
    "                    OptDB.setValue(nList[-1].linear_solver_options_prefix+\"pc_type\", \"lu\")\n",
    "                    OptDB.setValue(nList[-1].linear_solver_options_prefix+\"pc_factor_mat_solver_package\",\"superlu_dist\")\n",
    "                opts.save_dof = True\n",
    "                opts.dataDir='.'\n",
    "                opts.probDir='.'\n",
    "                opts.logLevel=7\n",
    "                opts.verbose=True\n",
    "                opts.viewMesh=True\n",
    "\n",
    "\n",
    "                ## Create numerical solution\n",
    "                ns = NumericalSolution.NS_base(so, pList, nList, so.sList, opts)\n",
    "\n",
    "\n",
    "                ## Start Simulation\n",
    "                simulation_thread = Thread(target = lambda : ns.calculateSolution('run1'))\n",
    "                simulation_thread.start()\n",
    "                \n",
    "            view.apply_sync(Setup_Simulation)\n",
    "            print 'Simulation Started'\n",
    "            ## Monitor Output\n",
    "            parUtilities.view=view\n",
    "            error=parUtilities.monitor_simulation(refresh=5.0)      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --targets 1\n",
    "\n",
    "\n",
    "import os   \n",
    "print test_name\n",
    "checkpath=os.path.exists('./'+test_name) \n",
    "if not checkpath:\n",
    "        os.mkdir(test_name)\n",
    "with open(test_name+'/opts.txt', 'w+') as fp:\n",
    "    fp.write('\\n'.join('%s %s' % (key , val) for key, val in plant.opts._asdict().items()))\n",
    "\n",
    "\n",
    "!cp tempFlume_p.xmf ./{test_name}/tempFlume_p.xmf\n",
    "!cp tempFlume_p.h5  ./{test_name}/tempFlume_p.h5\n",
    "\n",
    "if ns.systemStepController.converged():\n",
    "    error =False\n",
    "else:\n",
    "    error = True\n",
    "    \n",
    "if error:\n",
    "    !cp forceHistory_p.txt ./{test_name}/forceHistory_p.txt\n",
    "    !cp forceHistory_v.txt  ./{test_name}/forceHistory_v.txt\n",
    "    Exp_Status='Completed'\n",
    "else:\n",
    "    Exp_Status='Crashed'\n",
    "    \n",
    "print Exp_Status\n",
    "\n",
    "#!rm ./Results/{ExpTag}_p.xmf\n",
    "#!rm ./Results/{ExpTag}_p.h5\n",
    "#!cp tempFlume_p.xmf ./Results/{ExpTag}_p.xmf\n",
    "#!cp tempFlume_p.h5  ./Results/{ExpTag}_p.h5\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('DoE_TempFlume.xlsx', engine='xlsxwriter')\n",
    "\n",
    "if scale==21:\n",
    "    df4.loc[index,'Finished']=Exp_Status\n",
    "    df4.loc[index,'Time']=ns.systemStepController.t_system\n",
    "\n",
    "elif scale==25:\n",
    "    df5.loc[index,'Finished']=Exp_Status\n",
    "    df5.loc[index,'Time']=ns.systemStepController.t_system\n",
    "else:\n",
    "    print 'Scale Error'\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df1.to_excel(writer, sheet_name='Parameters')\n",
    "df2.to_excel(writer, sheet_name='Parameters Scale 1-21')\n",
    "df3.to_excel(writer, sheet_name='Parameters Scale 1-25')\n",
    "df4.to_excel(writer, sheet_name='Tests Scale 1-21')\n",
    "df5.to_excel(writer, sheet_name='Tests Scale 1-25')\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
